[{"authors":["admin"],"categories":null,"content":" Collaborative AI researcher/AI specialist at Viceph - an AI driven application for orthodontist Viceph.net. Assistant Manager of Advanced Technology Solution Department (ATSD) at Panasonic R\u0026amp;D Center Vietnam. Researching member at Vietnam Orthodontic Research Group [VORG] Senior Research Engineer with +8 years of full-time work experience of Computer Vision at Panasonic R\u0026amp;D Center Vietnam. Embedded Software engineer with +2 years of experience of Machine Vision/Embedded system at Foxconn Vietnam R\u0026amp;D Center Foxconn Company. Master\u0026rsquo;s graduate in Computer Science and Digital Image Processing from the Institute of photonics and communications at the National Kaohsiung University of Applied Sciences (Class of 2015). ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1676890155,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://nhthanh0809.github.io/mybiography/author/nguyen-huy-thanh/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/mybiography/author/nguyen-huy-thanh/","section":"authors","summary":"Collaborative AI researcher/AI specialist at Viceph - an AI driven application for orthodontist Viceph.net. Assistant Manager of Advanced Technology Solution Department (ATSD) at Panasonic R\u0026amp;D Center Vietnam. Researching member at Vietnam Orthodontic Research Group [VORG] Senior Research Engineer with +8 years of full-time work experience of Computer Vision at Panasonic R\u0026amp;D Center Vietnam.","tags":null,"title":"Nguyen Huy Thanh","type":"authors"},{"authors":null,"categories":null,"content":"This project focuses on fully automatically 3D BIM modeling using 3D point cloud data. In this project, we firstly collected 3D point cloud data of small room by using iPhone 12 Pro (integrated LiDAR sensor). The collected data then will be treated as input data of 3D point cloud recognition model. This deep learning model was trained on both public dataset (ScanNet V2) and our private dataset. For constructing 3D BIM model from predicted results, we developed an application based on REVIT APIs (C#) that can automatically construct 3D BIM model of room inside objects such as wall, floor, ceiling, tables, chairs, cabinets, etc. These 3D BIM models of the room can be integrated with our Digital Twin System or with IoT sensor database for simulation.\n","date":1596087480,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676890155,"objectID":"ee44b3b0e202cdd62ae6cba68d1292b0","permalink":"https://nhthanh0809.github.io/mybiography/project/3d_bim_auto_modeling/","publishdate":"2020-07-30T12:38:00+07:00","relpermalink":"/mybiography/project/3d_bim_auto_modeling/","section":"project","summary":"This project focuses on fully automatically 3D BIM modeling using 3D point cloud data. In this project, we firstly collected 3D point cloud data of small room by using iPhone 12 Pro (integrated LiDAR sensor).","tags":["Python","3D point cloud","Tensorflow","LiDAR","3D object recognition","REVIT APIs","3D BIM","C#","Database","IoT","Simulation"],"title":"Automated 3D BIM modeling for Digital Twin development","type":"project"},{"authors":null,"categories":null,"content":"Landmark identification is crucial in quantifying cephalometric analysis such as Steiner, Bjork, Ricketts, Kim, Nagasaki, etc. For applying these analysis to cephalometric image, dentist or orthodontist need to annotate some group of landmarks that corresponding to specified analysis. Manual annotation of landmarks is a tedious, laborious task and prone to human errors. Therefore, it\u0026rsquo;s necessary that they need an efficient automated application for landmark identification. In this project, we developed an online efficient AI driven tools for automatically detecting landmark on Cephalometry image. The core part of these tools is our developed deep learning model with backbone DenseNet121. This model was trained on both public dataset of Cephalometric image ISBI 2015 and private dataset. These tools currently has been integrated with other advanced technology tools in Viceph - an online AI driven application for orthodontist.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676890155,"objectID":"0199136e3d3b7ae7516ac59d753f7e37","permalink":"https://nhthanh0809.github.io/mybiography/project/ceph_landmark_det/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/mybiography/project/ceph_landmark_det/","section":"project","summary":"Landmark identification is crucial in quantifying cephalometric analysis such as Steiner, Bjork, Ricketts, Kim, Nagasaki, etc. For applying these analysis to cephalometric image, dentist or orthodontist need to annotate some group of landmarks that corresponding to specified analysis.","tags":["Python","Pytorch","Tensorflow","Medical image analysis","Cephalometric","Landmark detection","Deep learning","Bioimage informatics"],"title":"Automatic Cephalometric landmark detection","type":"project"},{"authors":null,"categories":null,"content":"Cervical vertebra maturation (CVM) staging in lateral cephalometric radiographs is an efficient method to determine skeletal maturation, as lateral cephalometric radiography is routinely required for orthodontic diagnosis and treatment planning in orthodontic practice with no additional radiographs required to assess the CVM stages. In this researching theme, we researched and developed an application applied AI algorithms that were trained on public dataset of Cephalometric image ISBI 2015 for classifying CVM stages. We firstly annotated CVM landmarks and CVM class label for 400 images in ISBI 2015. The annotated data were reviewed by 4 doctors (2 junior and 2 senior) to ensure reliability. Subsequently, the landmarks data first was trained with deep learning landmark detection model. The model achieved 99.42% Success Detection Rate (SDR) with respect to the 2mm precision range. After getting output from landmark detection model, we calculated our proposed cervical stage score values (the Figure) following to this User\u0026rsquo; Guide. These score values closely follow to CVM assessment features that were introduced by Baccetti et al.. Finally, these calculated score values and annotated CVM class labels were treated as input tabular data for training different classification model such as Multi-Layer Perceptron (MLP), CatBoost, XGBoost, and LightGBM. These models will output 6 CVM stages from CS1 to CS6 as final results. NOTE: These tools currently has been integrated with other advanced technology tools in Viceph - an online AI driven application for orthodontist.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676890155,"objectID":"38b29fa29486e873c8cb542a9dcf6e3c","permalink":"https://nhthanh0809.github.io/mybiography/project/cvm_classification/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/mybiography/project/cvm_classification/","section":"project","summary":"Cervical vertebra maturation (CVM) staging in lateral cephalometric radiographs is an efficient method to determine skeletal maturation, as lateral cephalometric radiography is routinely required for orthodontic diagnosis and treatment planning in orthodontic practice with no additional radiographs required to assess the CVM stages.","tags":["Python","Pytorch","Medical image analysis","Cephalometric","Landmark detection","Deep learning","Machine Learning","Catboost","XGBoost","LightGBM","Bioimage informatics"],"title":"Fully automated Cervical Vertebral Maturation assessment","type":"project"},{"authors":null,"categories":null,"content":"In this project, we focus on building-up an Instance segmentation model for recognizing drawing room layout data. We trained and tested our model (Unet architecture) on both public dataset (Cubicasa, R3D) and own dataset (more than 1000 images of drawing layout) To ensuring generalization of the trained model, we added CVF-FP dataset (public) to test set for evaluation. After AI model development, we deployed the model on Torchserve - a Pytorch model serving framework, and integrated to Kubenetes system. The AI model will be used for classifying room type, providing essential information for construction site works.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676890155,"objectID":"ed640f2eabb470a1fdf8f66b30f0efca","permalink":"https://nhthanh0809.github.io/mybiography/project/room_layout_recognition/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/mybiography/project/room_layout_recognition/","section":"project","summary":"In this project, we focus on building-up an Instance segmentation model for recognizing drawing room layout data. We trained and tested our model (Unet architecture) on both public dataset (Cubicasa, R3D) and own dataset (more than 1000 images of drawing layout) To ensuring generalization of the trained model, we added CVF-FP dataset (public) to test set for evaluation.","tags":["Python","Pytorch","Tensorflow","Deep Learning","Instance Segmentation","Torchserve","Docker","Kubenetes","Cloud"],"title":"Room layout recognition","type":"project"},{"authors":null,"categories":null,"content":"In this project, we focus on synthesizing 360 panoramic image data from 3D models without real image. We first collected 3D models of in-house objects such as table, curtain, chairs, air-conditioner, TV, etc from online storage. We then rendered these 3D model on a license software for visualizing 3D models. We chose this software because it has a function that allowing rendering objects under virtual 360 degrees camera. Using this software, we generated virtual multi-view video and images of collected 3D objects. Next, the videos and images will be processed by own developed tool allowing segment objects from background images. This tool synthesized 360 panoramic image data by putting segmented object images on different background. Finally, we trained some well-known object detectors (YoloV3, YoloV5, EfficientDet, Mask-RCNN, etc.) on the synthesized data then evaluated on 360 degree public dataset namely 360-Indoor The evaluation results show that this method is very efficient, low-cost and promising approach for synthesizing 360 image dataset.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676890155,"objectID":"c8f2c5264dfb4ae4597d8eb32efe1a9d","permalink":"https://nhthanh0809.github.io/mybiography/project/synthesizing_360degree_data/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/mybiography/project/synthesizing_360degree_data/","section":"project","summary":"In this project, we focus on synthesizing 360 panoramic image data from 3D models without real image. We first collected 3D models of in-house objects such as table, curtain, chairs, air-conditioner, TV, etc from online storage.","tags":["Python","Pytorch","Tensorflow","Deep Learning","3D","YoloV5","OpenCV","EfficientDet","Mask-RCNN"],"title":"Synthesizing data by using 3D object models","type":"project"},{"authors":null,"categories":null,"content":"In this project, we focus on optimizing video object tracking and segmentation model for running on digital still camera. We used the Siamese network based model for tracking object on input video. The model was trained on larger video dataset such as Youtube-VOS, ImageNet-VID 2015, etc. For optimizing the model, firstly we change backbone of the model from ResNet50 to MobileNetV1. We then re-trained and re-evaluated the modified model on above datasets. The evaluation show that while accuracy of the new model slightly decrease but performance significantly increase in comparison with the original one. Next step, we implemented quantization and pruning methods for compressing the model weight from Float 16 to Int 8, in order to it can run on edge device like digital camera.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676890155,"objectID":"b0cd2126b8dc434d3d2ed98cf32a1f7c","permalink":"https://nhthanh0809.github.io/mybiography/project/video_object_tracking_and_segmentation/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/mybiography/project/video_object_tracking_and_segmentation/","section":"project","summary":"In this project, we focus on optimizing video object tracking and segmentation model for running on digital still camera. We used the Siamese network based model for tracking object on input video.","tags":["Python","Pytorch","Tensorflow","Deep Learning","Objet Segmentation","Object Tracking","C++","MobileNet","Quantization","Pruning","Camera"],"title":"Video object tracking and segmentation for digital camera","type":"project"},{"authors":null,"categories":null,"content":" Researching some (xAI methods) for time series data. Eg: video action recognition. Implementing GradCAM, Contrastive Layer-wise Relevance Propagation (CLRP), Deep Taylor Decomposition algorithms for visualizing heat map (target feature map) that pretrained deep learning model focused on. Implementing some proposed xAI related approaches that can improve accuracy of the pretrained model. ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676890155,"objectID":"09c35dcab535c2fb8becda2265e87d9e","permalink":"https://nhthanh0809.github.io/mybiography/project/xai_for_video_recognition/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/mybiography/project/xai_for_video_recognition/","section":"project","summary":"Researching some (xAI methods) for time series data. Eg: video action recognition. Implementing GradCAM, Contrastive Layer-wise Relevance Propagation (CLRP), Deep Taylor Decomposition algorithms for visualizing heat map (target feature map) that pretrained deep learning model focused on.","tags":["Python","SlowFast","Pytorch","GradCAM","LRP","Tensor Decomposition","Action recognition"],"title":"xAI for video action recognition","type":"project"}]